{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kK9Nv-71UFe1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mn0HMSaRUY-7"
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bjO58dMgUg1W"
   },
   "outputs": [],
   "source": [
    "# Define column names based on dataset description\n",
    "names = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mKxAooXUUmH5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(url,names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yaOYDyruxu0D",
    "outputId": "d29ba9ca-8a2b-4fd5-f2e4-65cb039e4064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  x-box  y-box  width  height  onpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0          T      2      8      3       5      1      8     13      0      6   \n",
       "1          I      5     12      3       7      2     10      5      5      4   \n",
       "2          D      4     11      6       8      6     10      6      2      6   \n",
       "3          N      7     11      6       6      3      5      9      4      6   \n",
       "4          G      2      1      3       1      1      8      6      6      6   \n",
       "...      ...    ...    ...    ...     ...    ...    ...    ...    ...    ...   \n",
       "19995      D      2      2      3       3      2      7      7      7      6   \n",
       "19996      C      7     10      8       8      4      4      8      6      9   \n",
       "19997      T      6      9      6       7      5      6     11      3      7   \n",
       "19998      S      2      3      4       2      1      8      7      2      6   \n",
       "19999      A      4      9      6       6      2      9      5      3      1   \n",
       "\n",
       "       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0          6     10      8      0      8      0      8  \n",
       "1         13      3      9      2      8      4     10  \n",
       "2         10      3      7      3      7      3      9  \n",
       "3          4      4     10      6     10      2      8  \n",
       "4          6      5      9      1      7      5     10  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "19995      6      6      4      2      8      3      7  \n",
       "19996     12      9     13      2      9      3      7  \n",
       "19997     11      9      5      2     12      2      4  \n",
       "19998     10      6      8      1      9      5      8  \n",
       "19999      8      1      8      2      7      2      8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hnjAsmMDUqKk"
   },
   "outputs": [],
   "source": [
    "#seaparte features and target\n",
    "X = data.drop('letter',axis=1)\n",
    "y= data['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V3w2BJyMUySz"
   },
   "outputs": [],
   "source": [
    "#Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4rIss4W_U9Av"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y_encoded,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "osOCxUg-VJMp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 14:15:01.099877: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-22 14:15:01.100287: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 14:15:01.102410: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 14:15:01.108597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745311501.119077   27312 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745311501.122212   27312 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745311501.130013   27312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745311501.130021   27312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745311501.130022   27312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745311501.130023   27312 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-22 14:15:01.132542: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3iyxO-gaVQ8P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-22 14:15:02.318429: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "#DEfine model\n",
    "model = Sequential([\n",
    "    # First hidden layer with 64 neurons and ReLU activation function\n",
    "    Dense(64,activation='relu',input_shape=(X_train.shape[1],)),\n",
    "    # Second hidden layer with 64 neurons and ReLU activation function\n",
    "    Dense(64,activation='relu'),\n",
    "    # Output layer with neurons equal to the number of classes (26 for letters\n",
    "    # A-Z) and softmax activation function\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gqf0_DqfVnte"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcFUUOZ5VzJb",
    "outputId": "e67f5260-5834-4bb8-8725-28851949714a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3306 - loss: 2.5474 - val_accuracy: 0.6969 - val_loss: 1.1576\n",
      "Epoch 2/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7051 - loss: 1.0590 - val_accuracy: 0.7412 - val_loss: 0.9334\n",
      "Epoch 3/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.8760 - val_accuracy: 0.7638 - val_loss: 0.8103\n",
      "Epoch 4/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7821 - loss: 0.7642 - val_accuracy: 0.7887 - val_loss: 0.7411\n",
      "Epoch 5/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8017 - loss: 0.6797 - val_accuracy: 0.7981 - val_loss: 0.6966\n",
      "Epoch 6/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.6318 - val_accuracy: 0.8194 - val_loss: 0.6064\n",
      "Epoch 7/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.5704 - val_accuracy: 0.8275 - val_loss: 0.5686\n",
      "Epoch 8/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.5282 - val_accuracy: 0.8350 - val_loss: 0.5488\n",
      "Epoch 9/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8522 - loss: 0.4988 - val_accuracy: 0.8500 - val_loss: 0.5025\n",
      "Epoch 10/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8599 - loss: 0.4701 - val_accuracy: 0.8550 - val_loss: 0.4609\n",
      "Epoch 11/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.8603 - loss: 0.4381 - val_accuracy: 0.8644 - val_loss: 0.4445\n",
      "Epoch 12/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.4094 - val_accuracy: 0.8669 - val_loss: 0.4432\n",
      "Epoch 13/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.3943 - val_accuracy: 0.8731 - val_loss: 0.4002\n",
      "Epoch 14/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8864 - loss: 0.3717 - val_accuracy: 0.8813 - val_loss: 0.3900\n",
      "Epoch 15/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.3364 - val_accuracy: 0.8856 - val_loss: 0.3677\n",
      "Epoch 16/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8945 - loss: 0.3321 - val_accuracy: 0.8931 - val_loss: 0.3504\n",
      "Epoch 17/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3134 - val_accuracy: 0.8844 - val_loss: 0.3632\n",
      "Epoch 18/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.3049 - val_accuracy: 0.8988 - val_loss: 0.3282\n",
      "Epoch 19/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.3013 - val_accuracy: 0.9131 - val_loss: 0.3088\n",
      "Epoch 20/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9151 - loss: 0.2716 - val_accuracy: 0.9056 - val_loss: 0.3159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3cdf866d40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train,y_train, epochs=20, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s61F5nh4cIcs",
    "outputId": "8f1b8c9a-558c-47ed-d5ba-c1c1aceee003"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save the trained model\n",
    "model.save(\"letter_recognition_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deIM9hLfV66j",
    "outputId": "541525f6-de71-4828-cb7d-dea82af6adc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.8966 - loss: 0.3196\n",
      "Test Accuracy:  0.9027500152587891\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6-ETdeahcDnf"
   },
   "outputs": [],
   "source": [
    "#save the label encoder\n",
    "np.save(\"label_encoder_classes.npy\",label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6rrN9VsuWpYG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zslp-hMRaG4r"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess input dimensions\n",
    "def preprocess_input(dimensions):\n",
    "  # Convert dimensions to a numpy array and reshape it to match the input shape\n",
    "  # of the model\n",
    "  input_data=np.array(dimensions).reshape(1,-1)\n",
    "  return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xTVDjqOoaWPQ"
   },
   "outputs": [],
   "source": [
    "# Function to predict the output using the trained model\n",
    "def predict_output(model,input_data,label_encoder):\n",
    "   # Use the model to predict the output\n",
    "  predicted_class=np.argmax(model.predict(input_data),axis=-1)\n",
    "  # Convert the predicted class index back to the original letter\n",
    "  predicted_letter = label_encoder.inverse_transform(predicted_class)\n",
    "  return predicted_letter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9hK3TaRXatow"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model and label encoder\n",
    "model=load_model(\"letter_recognition_model.h5\")\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load(\"label_encoder_classes.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3D2_X26bI0s",
    "outputId": "38119add-073b-46ff-9800-1b2dea1b6b1a"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the dimensions separated by commas:  2,8,3,5,1,8,13,0,6,6,10,8,0,8,0,8\n"
     ]
    }
   ],
   "source": [
    "# Input dimensions dynamically from the user\n",
    "dimension_str = input(\"Enter the dimensions separated by commas: \")\n",
    "# Convert the input string to a list of integers\n",
    "dimensions = list(map(int, dimension_str.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6hxynRx5yRwp"
   },
   "outputs": [],
   "source": [
    "#Enter the dimensions separated by commas: 2,8,3,5,1,8,13,0,6,6,10,8,0,8,0,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0nfBCuB2dd7j"
   },
   "outputs": [],
   "source": [
    "# Preprocess the input dimensions\n",
    "input_data = preprocess_input(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eG1PWFvdynt",
    "outputId": "84521f93-12e9-4052-9b7d-098bcef43043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted Letter:  T\n"
     ]
    }
   ],
   "source": [
    "# Predict the output\n",
    "predicted_letter = predict_output(model, input_data,label_encoder)\n",
    "print(\"Predicted Letter: \",predicted_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2chBPI3heAkv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
